{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98666312",
   "metadata": {},
   "source": [
    "# 二、 图数据集加载与分析\n",
    "\n",
    "\n",
    "| 数据集          | 类型           | 描述                     | 节点数  | 边数    | 类别数 |\n",
    "|-----------------|----------------|--------------------------|---------|---------|--------|\n",
    "| Cora            | 同构图         | 引文网络，预测论文类别   | 2,708   | 5,429   | 7      |\n",
    "| CiteSeer        | 同构图         | 引文网络，预测论文类别   | 3,312   | 4,732   | 6      |\n",
    "| PubMed          | 同构图         | 生物医学引文网络         | 19,717  | 44,338  | 3      |\n",
    "| Reddit          | 大规模同构图   | Reddit帖子关系图         | 232,965 | 11,606,919 | 41    |\n",
    "| ogbn-arxiv      | 大规模同构图   | arXiv论文引用网络        | 169,343 | 1,166,243 | 40    |\n",
    "| ogbn-products   | 工业级同构图   | Amazon产品共购买图       | 2,449,029 | 61,859,140 | 47    |\n",
    "\n",
    "## 1. 环境配置\n",
    "\n",
    "设置Hugging Face镜像源，用于解决国内访问Hugging Face模型时的网络问题，确保能够正常下载和使用预训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28588d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "》》模型加载成功。\n"
     ]
    }
   ],
   "source": [
    "# 设置镜像\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "print(\"》》模型加载成功。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe979f",
   "metadata": {},
   "source": [
    "## 2. 加载数据集并保存到本地\n",
    "\n",
    "使用PyTorch Geometric (PyG)库加载Cora, CiteSeer, PubMed, Reddit数据集，Open Graph Benchmark (OGB)库加载ogbn_arxiv, ogbn_products数据集。\n",
    "\n",
    "这些都是适用于节点分类任务的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af3581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunqi/anaconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planetoid datasets loaded successfully.\n",
      "Reddit dataset loaded successfully.\n",
      "OGB datasets loaded successfully.\n",
      "All datasets downloaded.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid, Reddit  # Cora, CiteSeer, PubMed, Reddit\n",
    "from ogb.nodeproppred import PygNodePropPredDataset  # ogbn_arxiv, ogbn_products\n",
    "\n",
    "# 如果遇到torch.load()问题，则需要添加所有必要的安全全局变量\n",
    "import torch\n",
    "from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n",
    "from torch_geometric.data.storage import GlobalStorage\n",
    "\n",
    "torch.serialization.add_safe_globals([\n",
    "    DataEdgeAttr,\n",
    "    DataTensorAttr,\n",
    "    GlobalStorage\n",
    "    # 添加其他可能需要的类\n",
    "])\n",
    "\n",
    "# Cora, CiteSeer, PubMed\n",
    "cora_dataset = Planetoid(root='../datasets', name='Cora')\n",
    "citeseer_dataset = Planetoid(root='../datasets', name='CiteSeer')\n",
    "pubmed_dataset = Planetoid(root='../datasets', name='PubMed')\n",
    "print(\"Planetoid datasets loaded successfully.\")\n",
    "\n",
    "# Reddit\n",
    "reddit_dataset = Reddit(root='../datasets/Reddit')\n",
    "print(\"Reddit dataset loaded successfully.\")\n",
    "\n",
    "# ogbn_arxiv, ogbn_products\n",
    "ogbn_arxiv_dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='../datasets')\n",
    "ogbn_products_dataset = PygNodePropPredDataset(name='ogbn-products', root='../datasets')\n",
    "print(\"OGB datasets loaded successfully.\")\n",
    "\n",
    "print(\"All datasets downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80e583",
   "metadata": {},
   "source": [
    "## 3. 数据集分析\n",
    "\n",
    "逐个分析每个数据集的统计信息：\n",
    "\n",
    "其中，data = i[0]（实际是dataset[0]）输出如下：\n",
    "\n",
    "The first graph: Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
    "\n",
    "属性含义：\n",
    "- **x**： 节点特征矩阵 [节点数2708 × 特征维度1433]\n",
    "- **edge_index**： 边信息 [2维 × 边数10556] - 2代表边信息用相连接的两个节点的节点对表示\n",
    "- **y**： 节点标签 [节点数2708 × 1维] - 每个节点的类别\n",
    "- **train_mask/val_mask/test_mask**： 训练/验证/测试集划分 [节点数节点数2708 × 1维] - 布尔掩码\n",
    "- 掩码用于**划分数据集**，告诉模型在训练、验证、测试时分别使用哪些节点，0表示无表情，1表示有标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1eae5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset: Cora() ====================================================================================================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "\n",
      "The first graph: Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.90\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Number of training nodes: 140\n",
      "Number of validation nodes: 500\n",
      "Number of testing nodes: 1000\n",
      "Training node ratio: 5.17%\n",
      "Validation node ratio: 18.46%\n",
      "Testing node ratio: 36.93%\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "===== Dataset: CiteSeer() ====================================================================================================\n",
      "Number of graphs: 1\n",
      "Number of features: 3703\n",
      "Number of classes: 6\n",
      "\n",
      "The first graph: Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n",
      "Number of nodes: 3327\n",
      "Number of edges: 9104\n",
      "Average node degree: 2.74\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Number of training nodes: 120\n",
      "Number of validation nodes: 500\n",
      "Number of testing nodes: 1000\n",
      "Training node ratio: 3.61%\n",
      "Validation node ratio: 15.03%\n",
      "Testing node ratio: 30.06%\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "===== Dataset: PubMed() ====================================================================================================\n",
      "Number of graphs: 1\n",
      "Number of features: 500\n",
      "Number of classes: 3\n",
      "\n",
      "The first graph: Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n",
      "Number of nodes: 19717\n",
      "Number of edges: 88648\n",
      "Average node degree: 4.50\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Number of training nodes: 60\n",
      "Number of validation nodes: 500\n",
      "Number of testing nodes: 1000\n",
      "Training node ratio: 0.30%\n",
      "Validation node ratio: 2.54%\n",
      "Testing node ratio: 5.07%\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "===== Dataset: Reddit() ====================================================================================================\n",
      "Number of graphs: 1\n",
      "Number of features: 602\n",
      "Number of classes: 41\n",
      "\n",
      "The first graph: Data(x=[232965, 602], edge_index=[2, 114615892], y=[232965], train_mask=[232965], val_mask=[232965], test_mask=[232965])\n",
      "Number of nodes: 232965\n",
      "Number of edges: 114615892\n",
      "Average node degree: 491.99\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Number of training nodes: 153431\n",
      "Number of validation nodes: 23831\n",
      "Number of testing nodes: 55703\n",
      "Training node ratio: 65.86%\n",
      "Validation node ratio: 10.23%\n",
      "Testing node ratio: 23.91%\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "===== Dataset: PygNodePropPredDataset() ====================================================================================================\n",
      "Number of graphs: 1\n",
      "Number of features: 128\n",
      "Number of classes: 40\n",
      "\n",
      "The first graph: Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])\n",
      "Number of nodes: 169343\n",
      "Number of edges: 1166243\n",
      "Average node degree: 6.89\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "Number of training nodes: 90941\n",
      "Number of validation nodes: 29799\n",
      "Number of testing nodes: 48603\n",
      "Training node label rate: 0.54\n",
      "Validation node label rate: 0.18\n",
      "Testing node label rate: 0.29\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "===== Dataset: PygNodePropPredDataset() ====================================================================================================\n",
      "Number of graphs: 1\n",
      "Number of features: 100\n",
      "Number of classes: 47\n",
      "\n",
      "The first graph: Data(num_nodes=2449029, edge_index=[2, 123718280], x=[2449029, 100], y=[2449029, 1])\n",
      "Number of nodes: 2449029\n",
      "Number of edges: 123718280\n",
      "Average node degree: 50.52\n",
      "Has isolated nodes: True\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Number of training nodes: 196615\n",
      "Number of validation nodes: 39323\n",
      "Number of testing nodes: 2213091\n",
      "Training node label rate: 0.08\n",
      "Validation node label rate: 0.02\n",
      "Testing node label rate: 0.90\n",
      "====================================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [cora_dataset, citeseer_dataset, pubmed_dataset, reddit_dataset, ogbn_arxiv_dataset, ogbn_products_dataset]:\n",
    "    print(f'===== Dataset: {i} ' + '=' * 100)\n",
    "    # 数据集的统计信息\n",
    "    print(f'Number of graphs: {len(i)}')\n",
    "    print(f'Number of features: {i.num_features}')\n",
    "    print(f'Number of classes: {i.num_classes}')\n",
    "    print()\n",
    "\n",
    "    # 第一个图的统计信息\n",
    "    data = i[0]  # 数据集中的第一个图\n",
    "    print(f\"The first graph: {data}\")\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')\n",
    "\n",
    "    if i in [cora_dataset, citeseer_dataset, pubmed_dataset, reddit_dataset]:\n",
    "        print(f'Number of training nodes: {data.train_mask.sum().item()}')\n",
    "        print(f'Number of validation nodes: {data.val_mask.sum().item()}')\n",
    "        print(f'Number of testing nodes: {data.test_mask.sum().item()}')\n",
    "        print(f'Training node ratio: {data.train_mask.sum().item() / data.num_nodes:.2%}')\n",
    "        print(f'Validation node ratio: {data.val_mask.sum().item() / data.num_nodes:.2%}')\n",
    "        print(f'Testing node ratio: {data.test_mask.sum().item() / data.num_nodes:.2%}')\n",
    "    else:\n",
    "        # OGB数据集需要额外获取分割信息\n",
    "        split_idx = i.get_idx_split()\n",
    "        train_idx = split_idx['train']\n",
    "        valid_idx = split_idx['valid']\n",
    "        test_idx = split_idx['test']\n",
    "        print(f'Number of training nodes: {len(train_idx)}')\n",
    "        print(f'Number of validation nodes: {len(valid_idx)}')\n",
    "        print(f'Number of testing nodes: {len(test_idx)}')\n",
    "        print(f'Training node label rate: {len(train_idx) / data.num_nodes:.2f}')\n",
    "        print(f'Validation node label rate: {len(valid_idx) / data.num_nodes:.2f}')\n",
    "        print(f'Testing node label rate: {len(test_idx) / data.num_nodes:.2f}')\n",
    "\n",
    "    print('=' * 100)\n",
    "    print()\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
